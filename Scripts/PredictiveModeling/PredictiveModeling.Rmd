---
title: "Predictive Modeling Analysis"
author: "Ming Wan, Victor Yuan"
output: 
  github_document:
    toc: TRUE
---

# Step 0: Load Packages and Data
Load required packages:


```{r load packages}
#source("https://bioconductor.org/biocLite.R")
#biocLite('e1071')                                    # required for glmnet in caret
#biocLite('pROC')
library(pROC)
library(ggplot2)
library(limma)
library(caret)
library(dplyr)
#library(glmnet)
library(devtools)
library(kernlab)
install_github("ggbiplot", "vqv")
library(ggbiplot)
library(parallel)
library(foreach)
library(doParallel)
library(readxl)
```

```{r create multiple processes}
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
```

Read in pre-processed training data:
*Make sure the pre-processed data (data.txt, which is in data.zip) is present in the ../processed_data/ directory.

```{r load data}
#setwd('../')                                           # note: all of these relative file path calls work only for knitting

# load data (pre-processed training set)
train.data <- read.table('../../data/Processed Data/data.txt')
str(train.data)
## row names are CpG sites, column names are sample names
# transpose our data to have rows as observations, which is more convenient later on for building models
train.data <- as.data.frame(t(train.data))


# load metadata
design <- read.csv("../../data/Processed Data/des.txt", sep="\t", header=TRUE)
str(design)

row.names(train.data) == design$Samplename               # check that the samples are in same order
```

Read in test data:
```{r}
# read pre-processed test data
test.data <- read.table("../../Data/Processed Data/Test data/Matrix.processed.betas.placenta.txt", row.names = 1, header = T)
test.data <- as.data.frame(t(test.data))
sum(is.na(test.data)) # 52000 total entries that are NA
test.rmna <- test.data[, colSums(is.na(test.data)) == 0]  # remove columns with NAs present
test.design <-  read_excel("~/R Directory/ming_wan/stat540/team_Methylation-Badassays/data/Processed Data/Test data/metadata.GA_illumina_methylation.xls", 
    sheet = "Metadata", skip = 28)

```

```{r filter training data to contain the same CpGs as the test}
train.data <- train.data[,colnames(train.data) %in% colnames(test.rmna)]
dim(train.data)
```

We only keep CpG sites in training set that: 

* are also present in the test set

* does not have missing values in the test set

Which leaves `r dim(train.data)[2]` present in training set.

## Prefiltering cpgs 

It takes way too long to include all 400k sites when fitting elastic net logistic regression and SVM, so we will only inlcude sites with a large variance. We decided on a standard deviation threshold of 0.1.

```{r prefiltering based on SD}
train.sd <- apply(as.matrix(train.data), MARGIN = 2,FUN = sd)
sd(train.sd)
hist(train.sd)
abline(v = mean(train.sd))

# filter CpG sites with low s.d: only keep those with s.d higher than the average s.d across all CpG sites
train.gsd <- subset(train.sd, train.sd > 0.10)
str(train.gsd)
hist(train.gsd)

train.data.gsd <- train.data[,colnames(train.data) %in% names(train.gsd)]
```

We reduced the # of features to 'r ncol(train.data.gsd)' to reduce computation time. train.data.gsd is the working dataset

# Step 1: Unsupervised clustering:
---------------this section is exploratory analysis, we should move this to Nivi's exploratory file----------
As Rob suggested, PCA should be the precursor to supervised classification, more like an exploration.

## PCA on training data:

```{r pca}
pc.train <- prcomp(scale(train.data,center=T,scale = T))

# look at the eigenvalues
plot(pc.train, type = "l")
```
The `plot()` function returns a plot of the variances (y-axis) associated with the PCs (x-axis), which is useful to decide how many PCs to retain for further analysis.

```{r pca.summary}
summary(pc.train)
```
The `summary()` function describes the importance of the PCs. The first row describe again the standard deviation associated with each PC. The second row shows the proportion of the variance in the data explained by each component while the third row describe the cumulative proportion of explained variance.

```{r plot PCs}
g <- ggbiplot(pc.train, obs.scale = 1, var.scale = 1, 
              groups = design$Ethnicity, ellipse = TRUE, 
              circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
print(g)



PC123 <- data.frame(pc.train$x[,1:5])              # Take out first 3 PCs
PC123 <- PC123 %>% tibble::rownames_to_column('Samplename') %>%             # Put sample names into column to 
                    left_join(design, 'Samplename')                         # Join the metadata info 
head(PC123)            

ggplot(PC123, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Ethnicity)) +
  ggtitle('PC1 and PC2: Ethnicity')

ggplot(PC123, aes(x = PC1, y = PC3)) + 
  geom_point(aes(color = Ethnicity)) +
  ggtitle('PC1 and PC3: Ethnicity')

ggplot(PC123, aes(x = PC2, y = PC3)) + 
  geom_point(aes(color = Ethnicity)) +
  ggtitle('PC2 and PC3: Ethnicity')
```

We can see from plotting the first three principal components that our groups (Asian, Caucasian) do not seem to separate. This indicates that the main drivers of the variance in the data is something else.

```{r Plot other metadata}
ggplot(PC123, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = sex)) +
  ggtitle('Sex')

ggplot(PC123, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = ga)) +
  ggtitle('Gestational Age')

ggplot(PC123, aes(x = PC1, y = PC2)) + 
  geom_point(aes(color = Sample_Group)) +
  ggtitle('Sample Group')
```

It's not clear that our other variables are driving the variance in the data (sex, gestational age, and sample group).

```{r Scatter plot matrix first 5 PCs}
# scatter plot matrix for the first 5 PCs
splom(PC123[,c(2:6,10)], panel = panel.smoothScatter, raster = TRUE)
```

Plotting scatter plots of the top 5 PCs against ethnicity, none of the PCs can clearly separate samples by ethnicity, disappointing.

## PCA projection of loadings to test data:

We can use the predict function if we observe new data and want to predict their PCs values.

```{r}
# predict PCs for test set by projecting PC loadings to test data
predict(pc.train, new.data = test.data)
```

--------End of exploratory Analysis-----------

# Step 2: Supervised classification:


## logistic regression with elastic net regularization

```{r rename}
#renamed just so that I can copy Amrit's code

x.train <- train.data.gsd
y.train <- design$Ethnicity 
```

```{r subset data for faster run time, eval = FALSE, include = FALSE}
# since the data is very large (~450k rows), I will subset the data first to be able to play around with the code quickly.

x.train <- train.data.gsd[,1:1000] #takes the first 1000 columns (cpgs)
```

```{r Specify resampling method}
k = 5
M = 3

fitControl <- trainControl(method = "repeatedcv", 
													 number = k,                 # Number of folds
													 repeats = M,
													 ## Estimate class probabilities
													  classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = twoClassSummary,
													 savePredictions = TRUE,      # Saves ROC results
													 allowParallel = TRUE
													 )  

netGrid <- expand.grid(alpha = c(0.55, 0.75, 0.9),
                           lambda = c(0.077, 0.25))
```


```{r tune glmnet parameters}
set.seed(2017)                                         # training models requires the use of random #s. Setting (set.seed()) the randomness ensures reproducibility

#netGrid <- expand.grid(.alpha = seq(.05, 1, length = 15),
 #                                                   .lambda = c((1:5)/10)) # grid of tuning parameters to try out

system.time(netFit <- train(x = x.train,   # samples need to be in rows, features need to be columns
								y = y.train,                  
								method = "glmnet",                     # glmnet model
								trControl = fitControl,                # use fitControl to specify cross validation
								tuneGrid = netGrid,
								preProcess = c( "center", "scale"),    # Center and Scale the data
								metric = 'ROC')                        # ROC because distribution is slightly skewed
)

netFit
#saveRDS(netFit, './Data/Processed Data/netFit_alpha55_lambda_077_51pred.rds')
```

Cross validation with a fold of k = 5 (making each fold 9 samples large), was used to determine the optimal tuning parameters.

Horvath et al. (2013) uses an 'elastic net generalized linear model' to build an across-tissue DNAm predictor on age. Since our data is the same type, we'll try glmnet.

Horvath, S. (2013). DNA methylation age of human tissues and cell types. Genome Biology, 14(10), R115. http://doi.org/10.1186/gb-2013-14-10-r115
 
```{r examine results}
trellis.par.set(caretTheme())
ggplot(netFit)
ggplot(svmFit)

#heatmap of results
plot(netFit, metric = "ROC", plotType = "level",
     scales = list(x = list(rot = 90)))

plot(svmFit, metric = "ROC", plotType = "level",
     scales = list(x = list(rot = 90)))
```

```{r extract features}
predictorsNet <- predictors(netFit)
length(predictorsNet)

predictorsSvm <- predictors(svmFit)
length(predictorsSvm)
```
Looks like our model has chosen 'r length(predictors)' CpGs that can be used to predict ethnicity.

```{r plot top 35}
glmImp <- varImp(netFit, scale = F) # gives the t-statistic for all CpGs in the dataset
plot(glmImp, top = 51)
```

```{r Estimate test error by nested cv}
# this is adapted from Amrit's code from lec 19
#use repeated CV to estimate test performance
set.seed(2018)

# list of lists containing fold ids
folds <- lapply(1:M, function(i) createFolds(y.train, k = k))

system.time(netTesterror <- lapply(folds, function(i){
  lapply(i, function(j){
    # tune parameters with CV
    set.seed(2019)
    fitControl <- trainControl(method = "repeatedcv", 
													 number = k,                 
													 repeats = M,
													 classProbs = TRUE,
                           summaryFunction = twoClassSummary,
													 savePredictions = TRUE, allowParallel = T)
    
    
    # build elastic net classifier
    netFit <- train(x =  x.train[-j,],   
								y = y.train[-j],                  
								method = "glmnet",                     
								trControl = fitControl,
								preProcess = c( 'center', 'scale'),
								metric = 'ROC')   
    
    # Estimate probabilities of test predictions
    probTest <- predict(netFit, x.train[j,], type = 'prob')
    ethProb <- probTest[,'Asian']
    ethProb

  })
})
)
netTesterror
```

```{r Performance}
# Computer classification performance measures
# enet
Performance <- mapply(function(x, y){
  auc <- pROC::roc(y.train[unlist(x)], unlist(y),
                   direction ='<',
                   levels = c('Caucasian', 'Asian'),
                   percent = TRUE)
  list(tpr = auc$sensitivities,
       fpr = 100 - auc$specificities,
       auc = round(auc$auc, 2))
}, x = folds, y = netTesterror)
Performance
```

```{r ROC curve}
# plot ROC curve

plot(Performance['tpr',][[1]] ~ Performance['fpr',][[1]],
     type = 'l', col = 1, xlab = '100 - sensitivity',
     ylab = 'Sensitivity', main = 'Enet')
for(i in length(folds)){
  points(Performance['tpr',][[i]] ~ Performance['fpr',][[i]],
         type = 'l', col = 2)
}
text(x = 60, y = 40, labels =
       paste0('mean AUC = ', round(mean(unlist(Performance['auc',])), 1),
              '+/-', round(sd(unlist(Performance['auc',])), 1), '%'))
```

## Support Vector Machine

```{r train svm}
# Linear kernel SVM with CV
    fitControl <- trainControl(method = "cv", 
													 number = k,                 
													 classProbs = TRUE,
                           summaryFunction = twoClassSummary,
													 savePredictions = TRUE,
													 allowParallel = T)
    
    
    # build SVM classifier
    svm.fit <- train(x=x.train,
                        y= y.train,
                        method = "svmLinear",
                        preProc = c("center","scale"),
                        metric="ROC",
                        trControl=fitControl)

    svm.fit
```


```{r Estimate test error by nested cv}
# this is adapted from Amrit's code from lec 19
#use repeated CV to estimate test performance
set.seed(2018)

# list of lists containing fold ids
folds <- createFolds(y.train, k = k)

system.time(svmTesterror <- lapply(folds, function(j){
    # tune parameters with CV
    fitControl <- trainControl(method = "cv", 
													 number = k,                 
													 classProbs = TRUE,
                           summaryFunction = twoClassSummary,
													 savePredictions = TRUE, allowParallel = T)
    
    
    # build SVM classifier
    svmFit <- train(x=x.train[-j,],
                        y= y.train[-j],
                        method = "svmLinear",
                        preProc = c("center","scale"),
                        metric="ROC",
                        trControl=fitControl)
    
    # Estimate probabilities of test predictions
    probTest <- predict(svmFit, x.train[j,], type = 'prob')
    ethProb <- probTest[,'Asian']
    ethProb

})
)
#svmTesterror
```

```{r Performance}
# Computer classification performance measures
# enet
Performance <- mapply(function(x, y){
  auc <- pROC::roc(y.train[unlist(x)], unlist(y),
                   direction ='<',
                   levels = c('Caucasian', 'Asian'),
                   percent = TRUE)
  list(tpr = auc$sensitivities,
       fpr = 100 - auc$specificities,
       auc = round(auc$auc, 2))
}, x = folds, y = svmTesterror)
Performance
```

```{r ROC curve}
# plot ROC curve

plot(Performance['tpr',][[1]] ~ Performance['fpr',][[1]],
     type = 'l', col = 1, xlab = '100 - sensitivity',
     ylab = 'Sensitivity', main = 'Linear Kernel SVM')
for(i in length(folds)){
  points(Performance['tpr',][[i]] ~ Performance['fpr',][[i]],
         type = 'l', col = 2)
}
text(x = 60, y = 40, labels =
       paste0('mean AUC = ', round(mean(unlist(Performance['auc',])), 1),
              '+/-', round(sd(unlist(Performance['auc',])), 1), '%'))
```



# Step 3: Predict Ethnicity for Test Set

Use hierarchical clustering to visualize the cluster 
```{r predict ethnicity for test set}
x.test <- test.rmna

predictors(netFit) %in% rownames(test.data)

x.test <- x.test[, colnames(x.test) %in% colnames(train.data.gsd)]
sum(is.na(x.test)) # there shouldn't be NAs present -- predict() function cannot predict if there are missing values

select(x.test, contains(NA))
y.predict <- predict(netFit,  x.test)
svm.predict <- predict(svm.fit, x.test)

# Hierarchical clustering of predicted data, distance measured by Euclidean distance, average linkage
distance <- dist(y.predict, method="euclidean") 
cluster <- hclust(distance, method="average")
plot(cluster, hang=-1, label=y.predict)

```

# Step 4: Differentially Methylated Sites Between Test and Control

Our classifier predicts that all test samples are Caucasians. This raises suspicion as we expected some ethnic diversity in our test set. We can look at the differentially methylated CpG sites between training and test set to see how much difference these two data sets have.


Which set of CpG sites should we conduct DMA on?

1) all CpGs present in both data sets ( after removing sites with missing values in test);

```{r}

```


2) only CpGs with s.d. > 0.1;


```{r}
merged.sd <- rbind(x.train, x.test)
merged.design <-
  data.frame(Group = relevel(
    factor(c(rep("Train",nrow(x.train)),rep("Test", nrow(x.test)))), 
    ref = "Train"),
    row.names = rownames(merged.sd))
DesMat <- model.matrix(~ Group, merged.design)

```


3) only CpGs identified as predictors using elastic net;


```{r}

```

## Unsupervised Clustering PCA

```{r}
pc.merged <- prcomp(scale(merged.sd, cneter=T, scale = T))
PC1to5 <- data.frame(pc.merged$x[,1:5])              # Take out first 5 PCs
PC1to5 <- PC1to5 %>% tibble::rownames_to_column('Samplename') %>%             # Put sample names into column to 
                    left_join(design, 'Samplename')                         # Join the metadata info 
head(PC1to5)            

# scatter plot matrix for the first 5 PCs
splom(PC1to5[,c(2:6,10)], panel = panel.smoothScatter, raster = TRUE)

```


## Differential Methylation Analysis with Single Markers

```{r}
DMRfit <- lmFit(M.CGI, DesMat)
DMRfitEb <- eBayes(DMRfit)
cutoff <- 0.01
DMR <- topTable(DMRfitEb, coef = 'GroupALL', number = Inf, p.value = cutoff)
head(DMR)
```

